import time
import aiohttp
import asyncio
from tabulate import tabulate
from typing import Dict, List
from core.utils.llm import create_instance as create_llm_instance
from core.utils.tts import create_instance as create_tts_instance
from core.utils.util import read_config
import statistics
from config.settings import get_config_file
import inspect
import os
import logging

# è®¾ç½®å…¨å±€æ—¥å¿—çº§åˆ«ä¸ºWARNINGï¼ŒæŠ‘åˆ¶INFOçº§åˆ«æ—¥å¿—
logging.basicConfig(level=logging.WARNING)


class AsyncPerformanceTester:
    def __init__(self):
        self.config = read_config(get_config_file())
        self.test_sentences = self.config.get("module_test", {}).get(
            "test_sentences",
            ["ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", "What's the weather like today?",
             "è¯·ç”¨100å­—æ¦‚æ‹¬é‡å­è®¡ç®—çš„åŸºæœ¬åŸç†å’Œåº”ç”¨å‰æ™¯"]
        )
        self.results = {
            "llm": {},
            "tts": {},
            "combinations": []
        }

    async def _check_ollama_service(self, base_url: str, model_name: str) -> bool:
        """å¼‚æ­¥æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        async with aiohttp.ClientSession() as session:
            try:
                # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
                async with session.get(f"{base_url}/api/version") as response:
                    if response.status != 200:
                        print(f"ğŸš« OllamaæœåŠ¡æœªå¯åŠ¨æˆ–æ— æ³•è®¿é—®: {base_url}")
                        return False

                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
                async with session.get(f"{base_url}/api/tags") as response:
                    if response.status == 200:
                        data = await response.json()
                        models = data.get("models", [])
                        if not any(model["name"] == model_name for model in models):
                            print(f"ğŸš« Ollamaæ¨¡å‹ {model_name} æœªæ‰¾åˆ°ï¼Œè¯·å…ˆä½¿ç”¨ ollama pull {model_name} ä¸‹è½½")
                            return False
                    else:
                        print(f"ğŸš« æ— æ³•è·å–Ollamaæ¨¡å‹åˆ—è¡¨")
                        return False
                return True
            except Exception as e:
                print(f"ğŸš« æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {str(e)}")
                return False

    async def _test_tts(self, tts_name: str, config: Dict) -> Dict:
        """å¼‚æ­¥æµ‹è¯•å•ä¸ªTTSæ€§èƒ½"""
        try:
            logging.getLogger("core.providers.tts.base").setLevel(logging.WARNING)

            token_fields = ["access_token", "api_key", "token"]
            if any(field in config and any(x in config[field] for x in ["ä½ çš„", "placeholder"]) for field in
                   token_fields):
                print(f"â­ï¸  TTS {tts_name} æœªé…ç½®access_token/api_keyï¼Œå·²è·³è¿‡")
                return {"name": tts_name, "type": "tts", "errors": 1}

            module_type = config.get('type', tts_name)
            tts = create_tts_instance(
                module_type,
                config,
                delete_audio_file=True
            )

            print(f"ğŸµ æµ‹è¯• TTS: {tts_name}")

            tmp_file = tts.generate_filename()
            await tts.text_to_speak("è¿æ¥æµ‹è¯•", tmp_file)

            if not tmp_file or not os.path.exists(tmp_file):
                print(f"âŒ {tts_name} è¿æ¥å¤±è´¥")
                return {"name": tts_name, "type": "tts", "errors": 1}

            total_time = 0
            test_count = len(self.test_sentences[:2])

            for i, sentence in enumerate(self.test_sentences[:2], 1):
                start = time.time()
                tmp_file = tts.generate_filename()
                await tts.text_to_speak(sentence, tmp_file)
                duration = time.time() - start
                total_time += duration

                if tmp_file and os.path.exists(tmp_file):
                    print(f"âœ“ {tts_name} [{i}/{test_count}]")
                else:
                    print(f"âœ— {tts_name} [{i}/{test_count}]")
                    return {"name": tts_name, "type": "tts", "errors": 1}

            return {
                "name": tts_name,
                "type": "tts",
                "avg_time": total_time / test_count,
                "errors": 0
            }

        except Exception as e:
            print(f"âš ï¸ {tts_name} æµ‹è¯•å¤±è´¥: {str(e)}")
            return {"name": tts_name, "type": "tts", "errors": 1}

    async def _test_llm(self, llm_name: str, config: Dict) -> Dict:
        """å¼‚æ­¥æµ‹è¯•å•ä¸ªLLMæ€§èƒ½"""
        try:
            # å¯¹äºOllamaï¼Œè·³è¿‡api_keyæ£€æŸ¥å¹¶è¿›è¡Œç‰¹æ®Šå¤„ç†
            if llm_name == "Ollama":
                base_url = config.get('base_url', 'http://localhost:11434')
                model_name = config.get('model_name')
                if not model_name:
                    print(f"ğŸš« Ollamaæœªé…ç½®model_name")
                    return {"name": llm_name, "type": "llm", "errors": 1}

                if not await self._check_ollama_service(base_url, model_name):
                    return {"name": llm_name, "type": "llm", "errors": 1}
            else:
                if "api_key" in config and any(x in config["api_key"] for x in ["ä½ çš„", "placeholder", "sk-xxx"]):
                    print(f"ğŸš« è·³è¿‡æœªé…ç½®çš„LLM: {llm_name}")
                    return {"name": llm_name, "type": "llm", "errors": 1}

            # è·å–å®é™…ç±»å‹ï¼ˆå…¼å®¹æ—§é…ç½®ï¼‰
            module_type = config.get('type', llm_name)
            llm = create_llm_instance(module_type, config)

            # ç»Ÿä¸€ä½¿ç”¨UTF-8ç¼–ç 
            test_sentences = [s.encode('utf-8').decode('utf-8') for s in self.test_sentences]

            # åˆ›å»ºæ‰€æœ‰å¥å­çš„æµ‹è¯•ä»»åŠ¡
            sentence_tasks = []
            for sentence in test_sentences:
                sentence_tasks.append(self._test_single_sentence(llm_name, llm, sentence))

            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å¥å­æµ‹è¯•
            sentence_results = await asyncio.gather(*sentence_tasks)

            # å¤„ç†ç»“æœ
            valid_results = [r for r in sentence_results if r is not None]
            if not valid_results:
                print(f"âš ï¸  {llm_name} æ— æœ‰æ•ˆæ•°æ®ï¼Œå¯èƒ½é…ç½®é”™è¯¯")
                return {"name": llm_name, "type": "llm", "errors": 1}

            first_token_times = [r["first_token_time"] for r in valid_results]
            response_times = [r["response_time"] for r in valid_results]

            # è¿‡æ»¤å¼‚å¸¸æ•°æ®
            mean = statistics.mean(response_times)
            stdev = statistics.stdev(response_times) if len(response_times) > 1 else 0
            filtered_times = [t for t in response_times if t <= mean + 3 * stdev]

            if len(filtered_times) < len(test_sentences) * 0.5:
                print(f"âš ï¸  {llm_name} æœ‰æ•ˆæ•°æ®ä¸è¶³ï¼Œå¯èƒ½ç½‘ç»œä¸ç¨³å®š")
                return {"name": llm_name, "type": "llm", "errors": 1}

            return {
                "name": llm_name,
                "type": "llm",
                "avg_response": sum(response_times) / len(response_times),
                "avg_first_token": sum(first_token_times) / len(first_token_times),
                "std_first_token": statistics.stdev(first_token_times) if len(first_token_times) > 1 else 0,
                "std_response": statistics.stdev(response_times) if len(response_times) > 1 else 0,
                "errors": 0
            }
        except Exception as e:
            print(f"LLM {llm_name} æµ‹è¯•å¤±è´¥: {str(e)}")
            return {"name": llm_name, "type": "llm", "errors": 1}

    async def _test_single_sentence(self, llm_name: str, llm, sentence: str) -> Dict:
        """æµ‹è¯•å•ä¸ªå¥å­çš„æ€§èƒ½"""
        try:
            print(f"ğŸ“ {llm_name} å¼€å§‹æµ‹è¯•: {sentence[:20]}...")
            sentence_start = time.time()
            first_token_received = False
            first_token_time = None

            async def process_response():
                nonlocal first_token_received, first_token_time
                for chunk in llm.response("perf_test", [{"role": "user", "content": sentence}]):
                    if not first_token_received and chunk.strip() != '':
                        first_token_time = time.time() - sentence_start
                        first_token_received = True
                        print(f"âœ“ {llm_name} é¦–ä¸ªToken: {first_token_time:.3f}s")
                    yield chunk

            response_chunks = []
            async for chunk in process_response():
                response_chunks.append(chunk)

            response_time = time.time() - sentence_start
            print(f"âœ“ {llm_name} å®Œæˆå“åº”: {response_time:.3f}s")

            if first_token_time is None:
                first_token_time = response_time  # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°first tokenï¼Œä½¿ç”¨æ€»å“åº”æ—¶é—´

            return {
                "name": llm_name,
                "type": "llm",
                "first_token_time": first_token_time,
                "response_time": response_time
            }
        except Exception as e:
            print(f"âš ï¸ {llm_name} å¥å­æµ‹è¯•å¤±è´¥: {str(e)}")
            return None

    def _generate_combinations(self):
        """ç”Ÿæˆæœ€ä½³ç»„åˆå»ºè®®"""
        valid_llms = [
            k for k, v in self.results["llm"].items()
            if v["errors"] == 0 and v["avg_first_token"] >= 0.05
        ]
        valid_tts = [k for k, v in self.results["tts"].items() if v["errors"] == 0]

        # æ‰¾å‡ºåŸºå‡†å€¼
        min_first_token = min([self.results["llm"][llm]["avg_first_token"] for llm in valid_llms]) if valid_llms else 1
        min_tts_time = min([self.results["tts"][tts]["avg_time"] for tts in valid_tts]) if valid_tts else 1

        for llm in valid_llms:
            for tts in valid_tts:
                # è®¡ç®—ç›¸å¯¹æ€§èƒ½åˆ†æ•°ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
                llm_score = self.results["llm"][llm]["avg_first_token"] / min_first_token
                tts_score = self.results["tts"][tts]["avg_time"] / min_tts_time

                # è®¡ç®—ç¨³å®šæ€§åˆ†æ•°ï¼ˆæ ‡å‡†å·®/å¹³å‡å€¼ï¼Œè¶Šå°è¶Šç¨³å®šï¼‰
                llm_stability = self.results["llm"][llm]["std_first_token"] / self.results["llm"][llm][
                    "avg_first_token"]

                # ç»¼åˆå¾—åˆ†ï¼ˆè€ƒè™‘æ€§èƒ½å’Œç¨³å®šæ€§ï¼‰
                # æ€§èƒ½æƒé‡0.7ï¼Œç¨³å®šæ€§æƒé‡0.3
                llm_final_score = llm_score * 0.7 + llm_stability * 0.3

                # æ€»åˆ† = LLMå¾—åˆ†(70%) + TTSå¾—åˆ†(30%)
                total_score = llm_final_score * 0.7 + tts_score * 0.3

                self.results["combinations"].append({
                    "llm": llm,
                    "tts": tts,
                    "score": total_score,
                    "details": {
                        "llm_first_token": self.results["llm"][llm]["avg_first_token"],
                        "llm_stability": llm_stability,
                        "tts_time": self.results["tts"][tts]["avg_time"]
                    }
                })

        # åˆ†æ•°è¶Šå°è¶Šå¥½
        self.results["combinations"].sort(key=lambda x: x["score"])

    def _print_results(self):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        llm_table = []
        for name, data in self.results["llm"].items():
            if data["errors"] == 0:
                stability = data["std_first_token"] / data["avg_first_token"]
                llm_table.append([
                    name,  # ä¸éœ€è¦å›ºå®šå®½åº¦ï¼Œè®©tabulateè‡ªå·±å¤„ç†å¯¹é½
                    f"{data['avg_first_token']:.3f}ç§’",
                    f"{data['avg_response']:.3f}ç§’",
                    f"{stability:.3f}"
                ])

        if llm_table:
            print("\nLLM æ€§èƒ½æ’è¡Œ:")
            print(tabulate(
                llm_table,
                headers=["æ¨¡å‹åç§°", "é¦–å­—è€—æ—¶", "æ€»è€—æ—¶", "ç¨³å®šæ€§"],
                tablefmt="github",
                colalign=("left", "right", "right", "right"),
                disable_numparse=True
            ))
        else:
            print("\nâš ï¸ æ²¡æœ‰å¯ç”¨çš„LLMæ¨¡å—è¿›è¡Œæµ‹è¯•ã€‚")

        tts_table = []
        for name, data in self.results["tts"].items():
            if data["errors"] == 0:
                tts_table.append([
                    name,  # ä¸éœ€è¦å›ºå®šå®½åº¦
                    f"{data['avg_time']:.3f}ç§’"
                ])

        if tts_table:
            print("\nTTS æ€§èƒ½æ’è¡Œ:")
            print(tabulate(
                tts_table,
                headers=["æ¨¡å‹åç§°", "åˆæˆè€—æ—¶"],
                tablefmt="github",
                colalign=("left", "right"),
                disable_numparse=True
            ))
        else:
            print("\nâš ï¸ æ²¡æœ‰å¯ç”¨çš„TTSæ¨¡å—è¿›è¡Œæµ‹è¯•ã€‚")

        if self.results["combinations"]:
            print("\næ¨èé…ç½®ç»„åˆ (å¾—åˆ†è¶Šå°è¶Šå¥½):")
            combo_table = []
            for combo in self.results["combinations"][:5]:
                combo_table.append([
                    f"{combo['llm']} + {combo['tts']}",  # ä¸éœ€è¦å›ºå®šå®½åº¦
                    f"{combo['score']:.3f}",
                    f"{combo['details']['llm_first_token']:.3f}ç§’",
                    f"{combo['details']['llm_stability']:.3f}",
                    f"{combo['details']['tts_time']:.3f}ç§’"
                ])

            print(tabulate(
                combo_table,
                headers=["ç»„åˆæ–¹æ¡ˆ", "ç»¼åˆå¾—åˆ†", "LLMé¦–å­—è€—æ—¶", "ç¨³å®šæ€§", "TTSåˆæˆè€—æ—¶"],
                tablefmt="github",
                colalign=("left", "right", "right", "right", "right"),
                disable_numparse=True
            ))
        else:
            print("\nâš ï¸ æ²¡æœ‰å¯ç”¨çš„æ¨¡å—ç»„åˆå»ºè®®ã€‚")

    def _process_results(self, all_results):
        """å¤„ç†æµ‹è¯•ç»“æœ"""
        for result in all_results:
            if result["errors"] == 0:
                if result["type"] == "llm":
                    self.results["llm"][result["name"]] = result
                else:
                    self.results["tts"][result["name"]] = result

    async def run(self):
        """æ‰§è¡Œå…¨é‡å¼‚æ­¥æµ‹è¯•"""
        print("ğŸ” å¼€å§‹ç­›é€‰å¯ç”¨æ¨¡å—...")

        # åˆ›å»ºæ‰€æœ‰æµ‹è¯•ä»»åŠ¡
        all_tasks = []

        # LLMæµ‹è¯•ä»»åŠ¡
        for llm_name, config in self.config.get("LLM", {}).items():
            # æ£€æŸ¥é…ç½®æœ‰æ•ˆæ€§
            if llm_name == "CozeLLM":
                if any(x in config.get("bot_id", "") for x in ["ä½ çš„"]) \
                        or any(x in config.get("user_id", "") for x in ["ä½ çš„"]):
                    print(f"â­ï¸  LLM {llm_name} æœªé…ç½®bot_id/user_idï¼Œå·²è·³è¿‡")
                    continue
            elif "api_key" in config and any(x in config["api_key"] for x in ["ä½ çš„", "placeholder", "sk-xxx"]):
                print(f"â­ï¸  LLM {llm_name} æœªé…ç½®api_keyï¼Œå·²è·³è¿‡")
                continue

            # å¯¹äºOllamaï¼Œå…ˆæ£€æŸ¥æœåŠ¡çŠ¶æ€
            if llm_name == "Ollama":
                base_url = config.get('base_url', 'http://localhost:11434')
                model_name = config.get('model_name')
                if not model_name:
                    print(f"ğŸš« Ollamaæœªé…ç½®model_name")
                    continue

                if not await self._check_ollama_service(base_url, model_name):
                    continue

            print(f"ğŸ“‹ æ·»åŠ LLMæµ‹è¯•ä»»åŠ¡: {llm_name}")
            module_type = config.get('type', llm_name)
            llm = create_llm_instance(module_type, config)

            # ä¸ºæ¯ä¸ªå¥å­åˆ›å»ºç‹¬ç«‹ä»»åŠ¡
            for sentence in self.test_sentences:
                sentence = sentence.encode('utf-8').decode('utf-8')
                all_tasks.append(self._test_single_sentence(llm_name, llm, sentence))

        # TTSæµ‹è¯•ä»»åŠ¡
        for tts_name, config in self.config.get("TTS", {}).items():
            token_fields = ["access_token", "api_key", "token"]
            if any(field in config and any(x in config[field] for x in ["ä½ çš„", "placeholder"]) for field in
                   token_fields):
                print(f"â­ï¸  TTS {tts_name} æœªé…ç½®access_token/api_keyï¼Œå·²è·³è¿‡")
                continue
            print(f"ğŸµ æ·»åŠ TTSæµ‹è¯•ä»»åŠ¡: {tts_name}")
            all_tasks.append(self._test_tts(tts_name, config))

        print(
            f"\nâœ… æ‰¾åˆ° {len([t for t in all_tasks if 'test_single_sentence' in str(t)]) / len(self.test_sentences):.0f} ä¸ªå¯ç”¨LLMæ¨¡å—")
        print(f"âœ… æ‰¾åˆ° {len([t for t in all_tasks if '_test_tts' in str(t)])} ä¸ªå¯ç”¨TTSæ¨¡å—")
        print("\nâ³ å¼€å§‹å¹¶å‘æµ‹è¯•æ‰€æœ‰æ¨¡å—...\n")

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ä»»åŠ¡
        all_results = await asyncio.gather(*all_tasks, return_exceptions=True)

        # å¤„ç†LLMç»“æœ
        llm_results = {}
        for result in [r for r in all_results if r and isinstance(r, dict) and r.get("type") == "llm"]:
            llm_name = result["name"]
            if llm_name not in llm_results:
                llm_results[llm_name] = {
                    "name": llm_name,
                    "type": "llm",
                    "first_token_times": [],
                    "response_times": [],
                    "errors": 0
                }
            llm_results[llm_name]["first_token_times"].append(result["first_token_time"])
            llm_results[llm_name]["response_times"].append(result["response_time"])

        # è®¡ç®—LLMå¹³å‡å€¼å’Œæ ‡å‡†å·®
        for llm_name, data in llm_results.items():
            if len(data["first_token_times"]) >= len(self.test_sentences) * 0.5:
                self.results["llm"][llm_name] = {
                    "name": llm_name,
                    "type": "llm",
                    "avg_response": sum(data["response_times"]) / len(data["response_times"]),
                    "avg_first_token": sum(data["first_token_times"]) / len(data["first_token_times"]),
                    "std_first_token": statistics.stdev(data["first_token_times"]) if len(
                        data["first_token_times"]) > 1 else 0,
                    "std_response": statistics.stdev(data["response_times"]) if len(data["response_times"]) > 1 else 0,
                    "errors": 0
                }

        # å¤„ç†TTSç»“æœ
        for result in [r for r in all_results if r and isinstance(r, dict) and r.get("type") == "tts"]:
            if result["errors"] == 0:
                self.results["tts"][result["name"]] = result

        # ç”Ÿæˆç»„åˆå»ºè®®å¹¶æ‰“å°ç»“æœ
        print("\nğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        self._generate_combinations()
        self._print_results()


async def main():
    tester = AsyncPerformanceTester()
    await tester.run()


if __name__ == "__main__":
    asyncio.run(main())